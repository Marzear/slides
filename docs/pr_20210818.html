<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>Progress Report - 20210818</title>
    <link rel="shortcut icon" href="./favicon.ico" />
    <link rel="stylesheet" href="./dist/reset.css" />
    <link rel="stylesheet" href="./dist/reveal.css" />
    <link rel="stylesheet" href="_assets/theme/mytheme.css" id="theme" />
    <link rel="stylesheet" href="./css/highlight/zenburn.css" />


  </head>
  <body>
    <div class="reveal">
      <div class="slides"><section  data-markdown><script type="text/template">

# Progress Report - 20210818 <!-- .element: class="title" -->
##  <!-- .element: class="subtitle" -->

<div class="title-name">
2021.08.18 <br>
Yu-Hung, Wu
</div>
</script></section><section  data-markdown><script type="text/template">
## Outline

- Training Results
- Maximum Mutual Information Scoring Function (MMI)
- Perplexity w/ strides
</script></section><section ><section data-markdown><script type="text/template">
## Training Results  <!-- .element: class="section-title" -->
</script></section><section data-markdown><script type="text/template">
## Three Training Methods

1. Use ckiplab/gpt2-base-chinese as pretrained model (blue line)
2. Use ckiplab/gpt2-base-chinese as pretrained model and add 3 transformer layers on the top of GPT-2 (green line)
3. Use ckiplab/gpt2-base-chinese as pretrained model and add 3 transformer layers on the top of GPT-2; for the uppermost linear layer, use the pretrained weight in GPT-2 linear layer(red line)
</script></section><section data-markdown><script type="text/template">
## Results - Accuracy

![](attachments/2021-08-18-14-47-51.png) <!-- .element: class="img75" -->
</script></section><section data-markdown><script type="text/template">
## Results - Loss

![](attachments/2021-08-18-14-48-26.png) <!-- .element: class="img75" -->
</script></section><section data-markdown><script type="text/template">
## Results - Perplexity

![](attachments/2021-08-18-14-48-49.png) <!-- .element: class="img75" -->
</script></section><section data-markdown><script type="text/template">
## Results - Perplexity.

- Minimum of learn from pretrained: 26.5140
- Minimum of pretrained+transformer w/o linear weight: 26.9230
- Minimum of pretrained+transformer w/ linear weight: ***26.4309***
</script></section></section><section ><section data-markdown><script type="text/template">
## Maximum Mutual Information Scoring Function (MMI) <!-- .element: class="section-title" -->

https://arxiv.org/abs/1911.00536 <!-- .element: class="footnote" -->
</script></section><section data-markdown><script type="text/template">
## Maximum Mutual Information Scoring Function (MMI)

- From *DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation* (MS research group)
- Solved the problem that the response was sometimes too bland or uninformative
</script></section><section data-markdown><script type="text/template">
## Maximum Mutual Information Scoring Function (MMI).

- Given a dialogue in the training set:
  - A: How are you?
  - B: I'm fine, thanks. And you?
  - A: Great!

- To train the target model, we use the following as input:
  - [CLS]How are you?[SEP]I'm fine, thanks. And you?[SEP]Great![SEP]
</script></section><section data-markdown><script type="text/template">
## Maximum Mutual Information Scoring Function (MMI).

- Now, we train an additional "MMI model". The model's goal is to predict source sentences from given responses. Thus, the input is the reversed sentence of the original model:
  - [CLS]Great![SEP]I'm fine, thanks. And you?[SEP]How are you?[SEP]
</script></section><section data-markdown><script type="text/template">
## Maximum Mutual Information Scoring Function (MMI)..

- To use the MMI model:
    1. Use the target model to generate a set of responses, we denote it as *S*
    2. for each response in *S*, use the MMI model to calculate it's perplexity. The input is backwarded:
        - [CLS]response[SEP]Great![SEP]I'm fine, thanks. And you?[SEP]How are you?[SEP]
    3. Choose the one with least perplexity, this is the final response</script></section></section></div>
    </div>

    <script src="./dist/reveal.js"></script>

    <script src="./plugin/markdown/markdown.js"></script>
    <script src="./plugin/highlight/highlight.js"></script>
    <script src="./plugin/zoom/zoom.js"></script>
    <script src="./plugin/notes/notes.js"></script>
    <script src="./plugin/math/math.js"></script>
    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        plugins: [
          RevealMarkdown,
          RevealHighlight,
          RevealZoom,
          RevealNotes,
          RevealMath
        ]
      };

      // options from URL query string
      var queryOptions = Reveal().getQueryHash() || {};

      var options = extend(defaultOptions, {"controls":true,"progress":true,"history":true,"center":true,"slideNumber":"c","pdfMaxPagesPerSlide":1,"pdfSeparateFragments":true,"pdfPageHeightOffset":-8,"transition":"none"}, queryOptions);
    </script>


    <script>
      Reveal.initialize(options);
    </script>
  </body>
</html>
