<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>Progress Report - 20220622</title>
    <link rel="shortcut icon" href="./favicon.ico" />
    <link rel="stylesheet" href="./dist/reset.css" />
    <link rel="stylesheet" href="./dist/reveal.css" />
    <link rel="stylesheet" href="_assets/theme/mytheme.css" id="theme" />
    <link rel="stylesheet" href="./css/highlight/zenburn.css" />


  </head>
  <body>
    <div class="reveal">
      <div class="slides"><section  data-markdown><script type="text/template">

# Progress Report - 20220622 <!-- .element: class="title" -->

<div class="title-name">
2022.06.22 <br>
Yu-Hung Wu @ IIS, Academia Sinica
</div>
</script></section><section  data-markdown><script type="text/template">
## Outline

- Global Attention (GA) Investigation
- Stage 2 Implementation
</script></section><section  data-markdown><script type="text/template">
## Global Attention (GA) Investigation

| Setting                               | Testing F1 Score | Testing EM Score |
| ------------------------------------- | ---------------- | ---------------- |
| **window size = 128, w/o GA**         | 58.17            | 53.20            |
| **avg. $\sigma$ = 10, w/o GA**        | 38.80            | 34.12            |
| **fixed $\sigma$ = 10, w/o GA**       | 34.46            | 30.23            |
| avg. $\sigma$ = 10, w/ GA (baseline)  | 69.38            | 64.38            |
| **avg. $\sigma$ = 100, w/o GA**       | 51.20            | 46.39            |
| **fixed $\sigma$ = 100, w/o GA**      | 39.74            | 35.62            |
| avg. $\sigma$ = 100, w/ GA (baseline) | 72.07            | 67.13            |
</script></section><section  data-markdown><script type="text/template">
## Observations

1. Global Attention is a critical part in longformer (without GA, the performance dramatically decreases by 30 on both F1 and EM scores)

2. More $\sigma$ leads to better performance.

3. Letting the model to distribute $\sigma$ by itself leads to huge improvement.
</script></section><section  data-markdown><script type="text/template">
## Stage 2

* For the weights of $U_{d}$ and $W_{p}$, I initialize the weights from a previous experiment (average $\sigma$ = 100, no global attention, no thresholding) and then freeze them.

* The maximum of the window size of each token is 256, and my goal is to distribute $\sigma$s (that equal to $w = 128$) to each token.
</script></section><section  data-markdown><script type="text/template">
## Avg. $\sigma$ Calculation

* $U_{i, j} = e^{-\frac{(j-i)^{2}}{2\sigma}\}$, given a threshold $k$, we have $e^{-\frac{(j-i)^{2}}{2\sigma}\} > k$
* To get $\sigma$ by $k$ and $w$: $e^{-\frac{(j-i)^{2}}{2\sigma}\} = k$ 

    ➞  $-\frac{(j-i)^{2}}{2\sigma}\ = \log k$

    ➞  $\frac{(j-i)^{2}}{\sigma} = -2\log k$ 

    ➞  $\frac{w^{2}}{\sigma} = -2\log k$, where $w$ is the expected window size.

    ➞  $\sigma = \frac{w^{2}}{-2\log k}$

* For example, let $w = 128$, $k = 0.5$
  * $\frac{128^{2}}{\sigma} = -2\log 0.5$

    ➞ $\sigma$ = $\frac{128^{2}}{-2\log 0.5}$ 

    ➞ $\sigma = 11819$
</script></section><section  data-markdown><script type="text/template">
## Stage 2 Results

* There are two settings of the experiment:
  1. threshold $k = 0.5$, $\sigma = 11819$ (calculate from the formula in the previous slide)
  2. threshold $k = 0.6$, $\sigma = 16036$


<div id="left"> 

![](attachments/2022-06-20-15-28-48.png) <!-- .element: class="img100" -->

</div>
<div id="right">

![](attachments/2022-06-20-15-30-59.png) <!-- .element: class="img100" -->

</div>
</script></section><section  data-markdown><script type="text/template">
## Stage 2 Results.

* ALL reported performances do NOT include global attention.

1. Fixed window (baseline)

| Window size | Testing F1 Score | Testing EM Score |
| ----------- | ---------------- | ---------------- |
| 128         | 58.17            | 53.20            |
| 108         | 58.00            | 53.19            |

2. Fixed $\sigma$ (baseline) (w = 128)

| $\sigma$ | Testing F1 Score | Testing EM Score |
| -------- | ---------------- | ---------------- |
| 11819    | 59.04            | 54.17            |

3. Constrained $\sigma$ (max w = 256, avg w = 128)

| Threshold | Avg. $\sigma$ | ACTUAL avg. window size | Testing F1 Score | Testing EM Score |
| --------- | ------------- | ----------------------- | ---------------- | ---------------- |
| 0.5       | 11819         | **108**                 | 59.68            | 54.87            |
| 0.6       | 16036         | **110**                 | 60.19            | 55.32            |
</script></section><section  data-markdown><script type="text/template">
## Observations

1. Performance increased as window size increased.

2. Same as the experiments of adding global attention, multiplying the bell curve to attention score boosted the performance.

3. In the third experiment, the actual window size is usually smaller than the origin window size (128), however, the performance even increased.

4. The more the threshold (and the more the $\sigma$), the better the performance.

</script></section><section  data-markdown><script type="text/template">
## Window Size Visualization


<div id="left"> 

![](attachments/2022-06-22-00-18-18.png) <!-- .element: class="img110" -->

</div>
<div id="right">

![](attachments/2022-06-22-01-02-00.png) <!-- .element: class="img110" -->

</div>

* Both experiments have the peak at window size = 124.

</script></section><section  data-markdown><script type="text/template">
## Todo

1. Explore a way to add global attention to stage 2.

2. Read GPT-3 paper.</script></section></div>
    </div>

    <script src="./dist/reveal.js"></script>

    <script src="./plugin/markdown/markdown.js"></script>
    <script src="./plugin/highlight/highlight.js"></script>
    <script src="./plugin/zoom/zoom.js"></script>
    <script src="./plugin/notes/notes.js"></script>
    <script src="./plugin/math/math.js"></script>
    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        plugins: [
          RevealMarkdown,
          RevealHighlight,
          RevealZoom,
          RevealNotes,
          RevealMath
        ]
      };

      // options from URL query string
      var queryOptions = Reveal().getQueryHash() || {};

      var options = extend(defaultOptions, {"controls":true,"progress":true,"history":true,"center":true,"slideNumber":"c","pdfMaxPagesPerSlide":1,"pdfSeparateFragments":true,"pdfPageHeightOffset":-8,"transition":"none"}, queryOptions);
    </script>


    <script>
      Reveal.initialize(options);
    </script>
  </body>
</html>
