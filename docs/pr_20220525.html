<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>Progress Report - 20220525</title>
    <link rel="shortcut icon" href="./favicon.ico" />
    <link rel="stylesheet" href="./dist/reset.css" />
    <link rel="stylesheet" href="./dist/reveal.css" />
    <link rel="stylesheet" href="././theme/mytheme.css" id="theme" />
    <link rel="stylesheet" href="./css/highlight/zenburn.css" />


  </head>
  <body>
    <div class="reveal">
      <div class="slides"><section  data-markdown><script type="text/template">

# Progress Report - 20220525 <!-- .element: class="title" -->

<div class="title-name">
2022.05.25 <br>
Yu-Hung Wu @ IIS, Academia Sinica
</div>

https://marzear.github.io/slides/pr_20220525.html <!-- .element: class="footnote" -->
</script></section><section  data-markdown><script type="text/template">
## Outline

- Dynamic Longformer
- FJU-chatbot Dataset
</script></section><section ><section data-markdown><script type="text/template">
## Dynamic Longformer <!-- .element: class="section-title" -->
</script></section><section data-markdown><script type="text/template">
## Results

1. Dynamic standard deviation

| Exp Setting   | Starting $\sigma$ | Ending $\sigma$ | Testing F1 Score | Testing EM Score |
| ------------- | ----------------- | --------------- | ---------------- | ---------------- |
| **Normal LR** | 1.0               | 8.0             | 59.35            | 52.03            |
| **Normal LR** | 9.5               | 17.3            | 58.30            | 51.07            |
| LR*10         | 1.0               | 15.0            | 59.42            | 51.92            |
| LR*100        | 1.0               | 58.2            | 58.01            | 50.02            |

2. Fixed standard deviation

| Exp Setting                                 | Testing F1 Score | Testing EM Score |
| ------------------------------------------- | ---------------- | ---------------- |
| **Fixed $\sigma$  ($\sigma$=1.0, w=14)**    | 56.59            | 49.23            |
| **Fixed $\sigma$  ($\sigma$=9.5, w=44)**    | 58.47            | 50.96            |
| **Fixed $\sigma$  ($\sigma$=64, w=112)**    | 58.15            | 49.69            |
| **Fixed $\sigma$  ($\sigma$=1000, w=128)**  | 53.65            | 43.89            |
| **Fixed $\sigma$  ($\sigma$=50000, w=128)** | 53.30            | 43.41            |
</script></section><section data-markdown><script type="text/template">
## Results

3. Fixed window size (w/o standard deviation)

| Exp Setting                 | Testing F1 Score | Testing EM Score |
| --------------------------- | ---------------- | ---------------- |
| Fixed window size (256)     | 73.78            | 68.99            |
| **Fixed window size (128)** | 73.11            | 68.00            |
| Fixed window size (112)     | 72.84            | 67.72            |
| **Fixed window size (44)**  | 72.22            | 66.91            |
</script></section><section data-markdown><script type="text/template">
## Observations

1. Adding normal distribution to the attention weights has negative effect to the performance.

2. Using token embeddings to predict $\sigma$s has worked.

3. Increasing the learning rate of $U_{d}$ and $W_{p}$ (both contribute to the calculation of $\sigma$) improves the performance.

4. Increasing $\sigma$ has negative effect to the performance.
</script></section><section data-markdown><script type="text/template">
## Problems

* *Longformer* uses global attention + sliding window method.

* Global attention tokens attend to every tokens; every token attend to global attention tokens.

![](attachments/2022-05-24-12-16-29.png)
</script></section><section data-markdown><script type="text/template">
## Problems.

* Each token calculates its attention score base on global tokens + sliding window tokens.

* Our purpose is to only accelerate the memory efficiency of "sliding window tokens"; therefore, we only apply our method to sliding window tokens.

* Since all values of normal distribution PDF curve < 1, it decreases the attention weights itself.
</script></section><section data-markdown><script type="text/template">
## Problems..

* If $\sigma = 50000$, the curve is very close to uniform distribution.

* However, after the global attention tokens participating in the attention weight calculation, the weights of sliding window tokens are nearly ZERO!

![](attachments/2022-05-24-12-37-45.png)
</script></section><section data-markdown><script type="text/template">
## Modification

* Original normal distribution curve: $U_{i, j} = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{j-i}{\sigma}\right)^{2}\}$, where $\sigma$ is a learnable standard deviation of the normal distribution, $j$ is the position id of a key and $i$ is the position id of a query.

* Modified ~~normal distribution~~ bell curve: $U_{i, j} = e^{-\frac{1}{2}\left(\frac{j-i}{\sigma}\right)^{2}\}$.

* The maximum value of the bell curve is 1.

<div id="left"> 

![](attachments/2022-05-24-13-30-30.png) <!-- .element: class="img90" --> 

</div>
<div id="right"> 

![](attachments/2022-05-24-13-32-07.png) <!-- .element: class="img90" -->

 </div>
</script></section><section data-markdown><script type="text/template">
## $\sigma$ curve

* from 1 to 17,000, with just 20% of training steps.

![](attachments/2022-05-24-19-07-37.png) <!-- .element: class="img90" -->
</script></section></section><section ><section data-markdown><script type="text/template">
## FJU chatbot Dataset <!-- .element: class="section-title" -->
</script></section><section data-markdown><script type="text/template">
## Dataset

* The dataset are converted in JSON format.

```json
{
  "category":"relationship",
  "dialogue":[
    {
      "utterance":"我覺得跟阿公阿嬤好像很難聊天",
      "speaker":"user"
    },
    {
      "utterance":"怎麼會，你們不常見面嗎",
      "speaker":"bot"
    },
    {
      "utterance":"也不是，一個禮拜一次啊",
      "speaker":"user"
    },
    {
      "utterance":"那你有沒有學著好好聽他們說話",
      "speaker":"bot"
    },
    {
      "utterance":"沒有耶…",
      "speaker":"user"
    },
    {
      "utterance":"他們可能很想跟你分享，你下次可以試著問問他們之前小時候的故事啊～",
      "speaker":"bot"
    },
    {
      "utterance":"我下次努力試試～他們其實平時也很關心我",
      "speaker":"user"
    },
    {
      "utterance":"對啊，或你也可以關心他們一下，像有沒有睡好啊，吃飽沒之類的",
      "speaker":"bot"
    },
    {
      "utterance":"我知道了，我會努力的",
      "speaker":"user"
    },
    {
      "utterance":"加油加油！",
      "speaker":"bot"
    }
  ],
  "id":"4e90b44c-87b9-4764-a675-5f1c95233f0d",
  "university":"fju",
  "date":"20211201"
}
```
</script></section><section data-markdown><script type="text/template">
## Dataset.

* Each element represents a dialogue.

* Specification of each element:
  * ```category```: ```str```, represents the category of the dialogue.
    * Must be one of these: [food, clothing, housing, transportation, education, entertainment, relationship(人際關係), club(社團), work(工作/打工), covid(疫情)]
  * ```dialogue```: ```list```, Contains the utterances.
  * ```id```: ```str```, an unique id.
  * ```university```: ```str```, source of the dialogue.
    * Must be one of these: [fju(輔仁), ntue(國北教)]
  * ```date```: ```str```.
</script></section><section data-markdown><script type="text/template">
## Statistics

| Category       | 下新莊區輔仁大學 | 差點被台大合併的國北教 | **Total**  |
| -------------- | ---------------- | ---------------------- | ---------- |
| food           | 172              | 92                     | 264        |
| clothing       | 234              | 0                      | 234        |
| housing        | 102              | 23                     | 125        |
| transportation | 168              | 61                     | 229        |
| education      | 275              | 127                    | 402        |
| entertainment  | 383              | 232                    | 615        |
| club           | 33               | 0                      | 33         |
| relationship   | 145              | 149                    | 294        |
| work           | 20               | 21                     | 41         |
| covid          | 40               | 0                      | 40         |
| **total**      | 1572             | 705                    | ***2277*** |</script></section></section></div>
    </div>

    <script src="./dist/reveal.js"></script>

    <script src="./plugin/markdown/markdown.js"></script>
    <script src="./plugin/highlight/highlight.js"></script>
    <script src="./plugin/zoom/zoom.js"></script>
    <script src="./plugin/notes/notes.js"></script>
    <script src="./plugin/math/math.js"></script>
    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        plugins: [
          RevealMarkdown,
          RevealHighlight,
          RevealZoom,
          RevealNotes,
          RevealMath
        ]
      };

      // options from URL query string
      var queryOptions = Reveal().getQueryHash() || {};

      var options = extend(defaultOptions, {"controls":true,"progress":true,"history":true,"center":true,"slideNumber":"h.v","pdfMaxPagesPerSlide":1,"pdfSeparateFragments":true,"pdfPageHeightOffset":-1,"transition":"none"}, queryOptions);
    </script>


    <script>
      Reveal.initialize(options);
    </script>
  </body>
</html>
