---
title: 'Progress Report - 20220608'
# titie: 'Seminar - '
date: "2022-06-08"
theme: theme/mytheme.css
external_link: ""
---

# Progress Report - 20220608 <!-- .element: class="title" -->

<div class="title-name">
2022.06.08 <br>
Yu-Hung Wu @ IIS, Academia Sinica
</div>

https://marzear.github.io/slides/pr_20220608.html <!-- .element: class="footnote" -->

---

## Results

1. Fixed $\sigma$ (window size = 128)

| Setting                                 | Testing F1 Score | Testing EM Score |
| --------------------------------------- | ---------------- | ---------------- |
| **Fixed $\sigma$  ($\sigma$=1, w=14)**  | 64.87            | 59.48            |
| **Fixed $\sigma$  ($\sigma$=10, w=45)** | 69.38            | 64.38            |
| **Fixed $\sigma$  ($\sigma$=100)**      | 72.07            | 67.13            |
| **Fixed $\sigma$  ($\sigma$=1000)**     | 73.10            | 68.21            |
| **Fixed $\sigma$  ($\sigma$=25000)**    | 73.40            | 68.23            |
| **Fixed $\sigma$  ($\sigma$=50000)**    | 73.63            | 68.56            |
| *Fixed window size (128) (Baseline)*    | *73.11*          | *68.00*          |

2. Dynamic $\sigma$ (unconstrained)

| Setting            | Starting $\sigma$ | Ending $\sigma$ | Testing F1 Score | Testing EM Score |
| ------------------ | ----------------- | --------------- | ---------------- | ---------------- |
| **LR = $3e^{-4}$** | 1.0               | 102.3           | 70.56            | 65.53            |
| **LR = $3e^{-2}$** | 1.0               | 23635.3         | 72.75            | 67.52            |

---

## Window Size Constraint

- We can obtain the $\sigma$ of all queries in a single layer by using the following formula:
    - $\Sigma = U_{d}∗tanh(Q*W_{p})$, where $Q$ is a matrix that contains ALL queries $[q_{0}, q_{1}, q_{2}...q_{n-1}]$ and has shape $[n, 768]$, $\Sigma$ is a vector that contains the $\sigma$ of ALL queries and has shape $[n, 1]$.

- To apply constraints to the above formula, first set the average of $\sigma$ as a constant value $C$. Thus, the constrained $\Sigma$ is: $\Sigma^{\prime} = C * n * softmax(U_{d}∗tanh(Q*W_{p}))$

---

## Results

| Setting                         | Testing F1 Score | Testing EM Score |
| ------------------------------- | ---------------- | ---------------- |
| **avg. $\sigma$ = 10**          | 70.67            | 65.71            |
| Fixed $\sigma$ = 10 (baseline)  | 69.38            | 64.38            |
| **avg. $\sigma$ = 100**         | 71.93            | 67.08            |
| Fixed $\sigma$ = 100 (baseline) | 72.07            | 67.13            |
<div id="left"> 

![](attachments/2022-05-30-12-34-03.png) <!-- .element: class="img110" -->

</div>
<div id="right">

![](attachments/2022-05-30-12-40-57.png) <!-- .element: class="img110" -->
 
</div>
---

## $\sigma$'s Standard Deviation

<div id="left"> 

![](attachments/2022-06-08-00-16-06.png) <!-- .element: class="img130" -->

</div>
<div id="right">

![](attachments/2022-06-08-00-18-12.png) <!-- .element: class="img130" -->

</div>

---

## Todo

- A two-stage training:
    1. Use a smaller scale to train a strategy of sliding window
        - Update the sliding window network and the backbone model simultaneously (without slicing the window dynamically).

    2. **Update the model with a large scale using the learned strategy**
        - **Only update the backbone model (using the slicing window strategy to optimize the computational cost)**


---

## Global Attention (GA) Investigation

| Setting                         | **Validation** F1 Score | **Validation** EM Score |
| ------------------------------- | ---------------- | ---------------- |
| **avg. $\sigma$ = 10, w/o GA**       | 40.09            | 35.42            |
| **fixed $\sigma$ = 10, w/o GA**      | 34.60            | 30.29            |
| **avg. $\sigma$ = 10, w/ GA** (baseline)      |70.67|65.71|

- Preliminary observation: In **avg. $\sigma$ = 10, w/o GA** experiment, padding tokens share less $\sigma$ then others.

---

## Seminar Paper

- Topic: *ProphetChat: Enhancing Dialogue Generation with Simulation of Future Conversation*

- Utilizing the simulated dialogue futures in the inference phase to enhance response generation.

- Estimate $P(response|history, feature)$.